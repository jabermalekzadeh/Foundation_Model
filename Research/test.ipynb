{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bafdfa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koorosh/Documents/Coding/Foundation_Model/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 25.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model to divice\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "local_model_path = \"llama2-7b-chat\"  # or full path if you prefer\n",
    "current_path = os.getcwd()\n",
    "parent_path = os.path.dirname(current_path)\n",
    "path = os.path.join(parent_path, local_model_path)\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load tokenizer from local dir\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    path,\n",
    "    dtype = torch.float16,\n",
    "    local_files_only = True\n",
    "    )\n",
    "\n",
    "model.to(device)\n",
    "print('model to divice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5d56b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell what is optoacosutic.\n",
      "Optoacoustic refers to the use of light (opto) to generate sound (acoustic) for imaging or sensing applications. Optoacoustic techniques use light to excite molecules or particles in a sample, which then emit sound waves that can be detected and used to create images or measure properties of the sample. This approach offers several advantages over traditional imaging methods, including higher resolution, deeper penetration, and non-invasive imaging.\n",
      "\n",
      "In optoacoustic imaging, light is directed at a sample, and the absorption or scattering of the light by the sample causes the sample to heat up or vibrate. These changes in temperature or pressure generate sound waves that can be detected using an ultrasound transducer. The resulting image shows the distribution of light absorption or scattering in the sample.\n",
      "\n",
      "Optoacoustic techniques have been used in a variety of applications, including\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"Tell what is optoacosutic.\"\n",
    ")\n",
    "\n",
    "input = tokenizer(prompt, return_tensors = 'pt').to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "        \n",
    "    output_ids = model.generate(\n",
    "        **input,\n",
    "        max_new_tokens = 200,\n",
    "        do_sample = True,\n",
    "        temperature = 0.7,\n",
    "        top_p = 0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_time=20,\n",
    "    )\n",
    "\n",
    "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
